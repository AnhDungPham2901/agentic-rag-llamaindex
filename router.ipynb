{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a8d788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a50d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cac3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"The Era of Experience Paper.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c08f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2650ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b134c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093ab769",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e329add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "069d8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c740bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The question asks for a summary of the document, which aligns with the purpose of choice 1, as it is useful for summarization questions..\n",
      "\u001b[0mThe document discusses the transition to a new era in artificial intelligence characterized by agents that learn predominantly from their own experiences rather than relying solely on human-generated data. This \"Era of Experience\" aims to overcome the limitations of current AI systems, which have reached a plateau in performance due to the finite nature of human data. \n",
      "\n",
      "Key features of this new era include:\n",
      "\n",
      "1. **Continuous Learning**: Agents will learn from ongoing streams of experience, allowing them to adapt over time and pursue long-term goals, unlike current systems that operate in short, isolated interactions.\n",
      "\n",
      "2. **Autonomous Interaction**: Agents will engage with their environments through rich actions and observations, moving beyond human-centric communication to more autonomous behaviors.\n",
      "\n",
      "3. **Grounded Rewards**: Instead of relying on human judgments for feedback, agents will utilize rewards based on real-world signals, enabling them to discover new strategies and improve their performance beyond human capabilities.\n",
      "\n",
      "4. **Innovative Planning and Reasoning**: The document suggests that agents will develop new reasoning methods grounded in real-world interactions, allowing them to plan actions based on predicted outcomes rather than imitating human thought processes.\n",
      "\n",
      "5. **Potential and Risks**: While the era of experience promises significant advancements in AI capabilities, such as accelerating scientific discovery and personalizing assistance, it also raises concerns about job displacement, safety, and the interpretability of AI systems.\n",
      "\n",
      "Overall, the document emphasizes the transformative potential of experiential learning in AI, which could lead to superhuman intelligence and innovative solutions across various domains.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "309fe84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac5163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question asks for specific information about potential and risks mentioned in the document, which aligns with retrieving specific context from the MetaGPT paper..\n",
      "\u001b[0mThe document outlines several potential benefits and risks associated with the era of experience in AI. \n",
      "\n",
      "On the potential side, experiential learning is expected to unlock unprecedented capabilities, such as personalized assistants that adapt to individual needs over time and the acceleration of scientific discovery. AI agents could autonomously design and conduct experiments, rapidly exploring new frontiers in fields like materials science and medicine, leading to the development of novel materials, drugs, and technologies.\n",
      "\n",
      "Conversely, the risks include job displacement due to increased productivity and the potential misuse of AI. There are heightened concerns regarding agents that can autonomously interact with the world over extended periods, which may reduce human oversight and necessitate a high level of trust and responsibility. Additionally, moving away from human-derived data could make future AI systems harder to interpret, and while experiential learning may increase safety risks, it could also provide important safety benefits by allowing agents to adapt their behavior based on environmental changes and human feedback.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are potential and risks mentioned in the document?\",\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "962ea939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='ceb781fd-efad-4642-b943-aee0380ad7d1', embedding=None, metadata={'page_label': '8', 'file_name': 'The Era of Experience Paper.pdf', 'file_path': 'The Era of Experience Paper.pdf', 'file_type': 'application/pdf', 'file_size': 226196, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7523dd9c-986d-4993-93a3-5f73dff80797', node_type='4', metadata={'page_label': '8', 'file_name': 'The Era of Experience Paper.pdf', 'file_path': 'The Era of Experience Paper.pdf', 'file_type': 'application/pdf', 'file_size': 226196, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21'}, hash='07b9cbc4593cce78a8ef8a5f17ceb3dcb70560f4a4b111a931cbb0e383f7a90d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='capabilities promises to boost productivity, these improvements could also lead to job displacement. Agents\\nmay even be able to exhibit capabilities previously considered the exclusive realm of humanity, such as long-\\nterm problem-solving, innovation, and a deep understanding of real world consequences.\\nFurthermore, whilst general concerns exist around the potential misuse of any AI, heightened risks may\\narise from agents that can autonomously interact with the world over extended periods of time to achieve\\nlong-term goals. By default, this provides fewer opportunities for humans to intervene and mediate the\\nagent’s actions, and therefore requires a high bar of trust and responsibility. Moving away from human data\\nand human modes of thinking may also make future AI systems harder to interpret.\\nHowever, whilst acknowledging that experiential learning will increase certain safety risks, and that fur-\\nther research is surely required to ensure a safe transition into the era of experience, we should also recognise\\nthat it may also provide some important safety benefits.\\nFirstly, an experiential agent is aware of the environment it is situated within, and its behaviour can adapt\\nover time to changes in that environment. Any pre-programmed system, including a fixed AI system, can\\nbe unaware of its environmental context, and become maladapted to the changing world into which it is\\ndeployed. For example, a critical piece of hardware may malfunction, a pandemic might cause rapid societal\\nchange, or a new scientific discovery may trigger a cascade of rapid technological developments. By contrast,\\nan experiential agent could observe and learn to circumvent malfunctioning hardware, adjust to rapid societal\\nchange, or embrace and build upon new science and technology. Perhaps even more importantly, the agent\\ncould recognise when its behaviour is triggering human concern, dissatisfaction, or distress, and adaptively\\nmodify its behaviour to avoid these negative consequences.\\nSecondly, the agent’s reward function may itself be adapted through experience, for example using the bi-\\nlevel optimisation described earlier (see Rewards). Importantly, this means that misaligned reward functions\\ncan often be incrementally corrected over time by trial and error. For example, rather than blindly optimising\\na signal, such as the maximisation of paperclips [5], the reward function could be modified, based upon\\nindications of human concern, before paperclip production consumes all of the Earth’s resources. This is\\nanalogous to the way that humans set goals for each other, and then adapt those goals if they observe people\\ngaming the system, neglecting long-term well-being, or causing undesired negative consequences; although\\nalso like human goal-setting, there is no guarantee of perfect alignment.\\nFinally, advancements relying on physical experience are inherently constrained by the time it takes to\\nexecute actions in the real world and observe their consequences. For example, the development of a new\\ndrug, even with AI-assisted design, still requires real-world trials that cannot be completed overnight. This\\nmay provide a natural brake on the pace of potential AI self-improvement.\\nConclusion\\nThe era of experience marks a pivotal moment in the evolution of AI. Building on today’s strong foundations,\\nbut moving beyond the limitations of human-derived data, agents will increasingly learn from their own\\ninteractions with the world. Agents will autonomously interact with environments through rich observations\\nand actions. They will continue to adapt over the course of lifelong streams of experience. Their goals\\nwill be directable towards any combination of grounded signals. Furthermore, agents will utilise powerful\\nnon-human reasoning, and construct plans that are grounded in the consequences of the agent’s actions upon\\nits environment. Ultimately, experiential data will eclipse the scale and quality of human generated data.\\nThis paradigm shift, accompanied by algorithmic advancements in RL, will unlock in many domains new\\ncapabilities that surpass those possessed by any human.\\n8', mimetype='text/plain', start_char_idx=0, end_char_idx=4121, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3482270345803283),\n",
       " NodeWithScore(node=TextNode(id_='253470e6-102e-4662-83cb-c76d76d8b136', embedding=None, metadata={'page_label': '7', 'file_name': 'The Era of Experience Paper.pdf', 'file_path': 'The Era of Experience Paper.pdf', 'file_type': 'application/pdf', 'file_size': 226196, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='44fed0df-89ea-41e5-bd85-eb11b4b7d858', node_type='4', metadata={'page_label': '7', 'file_name': 'The Era of Experience Paper.pdf', 'file_path': 'The Era of Experience Paper.pdf', 'file_type': 'application/pdf', 'file_size': 226196, 'creation_date': '2025-04-21', 'last_modified_date': '2025-04-21'}, hash='c97a3cc00a7e0b9a516b0ae41dd1bb7f35a82685e01bf4ff11a8fe921e5887cb')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Reinforcement Learning Methods\\nReinforcement learning (RL) has a rich history that is deeply rooted in autonomous learning, where agents\\nlearn for themselves through direct interaction with their environment. Early RL research yielded a suite of\\npowerful concepts and algorithms. For example, temporal difference learning [35] enabled agents to estimate\\nfuture rewards, leading to breakthroughs such as superhuman performance in backgammon [39]. Exploration\\ntechniques, driven by optimism or curiosity, were developed to help agents discover creative new behaviors\\nand avoid getting stuck in suboptimal routines [2]. Methods like the Dyna algorithm enabled agents to\\nbuild and learn from models of their world, allowing them to plan and reason about future actions [36,\\n29]. Concepts like options and inter/intra-option learning facilitated temporal abstraction, enabling agents to\\nreason over longer timescales and break down complex tasks into manageable sub-goals [38].\\nThe rise of human-centric LLMs, however, shifted the focus away from autonomous learning and towards\\nleveraging human knowledge. Techniques like RLHF (Reinforcement Learning from Human Feedback) [9,\\n25] and methods for aligning language models with human reasoning [44] proved incredibly effective, driving\\nrapid progress in AI capabilities. These approaches, while powerful, often bypassed core RL concepts: RLHF\\nside-stepped the need for value functions by invoking human experts in place of machine-estimated values,\\nstrong priors from human data reduced the reliance on exploration, and reasoning in human-centric terms\\nlessened the need for world models and temporal abstraction.\\nHowever, it could be argued that the shift in paradigm has thrown out the baby with the bathwater. While\\nhuman-centric RL has enabled an unprecedented breadth of behaviours, it has also imposed a new ceiling\\non the agent’s performance: agents cannot go beyond existing human knowledge. Furthermore, the era of\\nhuman data has focused predominantly on RL methods that are designed for short episodes of ungrounded,\\nhuman interaction, and are not suitable for long streams of grounded, autonomous interaction.\\nThe era of experience presents an opportunity to revisit and improve classic RL concepts. This era will\\nbring new ways to think about reward functions that are flexibly grounded in observational data. It will\\nrevisit value functions and methods to estimate them from long streams with as yet incomplete sequences. It\\nwill bring principled yet practical methods for real-world exploration that discover new behaviours that are\\nradically different from human priors. Novel approaches to world models will be developed that capture the\\ncomplexities of grounded interactions. New methods for temporal abstraction will allow agents to reason, in\\nterms of experience, over ever-longer time horizons. By building upon the foundations of RL and adapting\\nits core principles to the challenges of this new era, we can unlock the full potential of autonomous learning\\nand pave the way to truly superhuman intelligence.\\nConsequences\\nThe advent of the era of experience, where AI agents learn from their interactions with the world, promises a\\nfuture profoundly different from anything we have seen before. This new paradigm, while offering immense\\npotential, also presents important risks and challenges that demand careful consideration, including but not\\nlimited to the following points.\\nOn the positive side, experiential learning will unlock unprecedented capabilities. In everyday life, per-\\nsonalized assistants will leverage continuous streams of experience to adapt to individuals’ health, educa-\\ntional, or professional needs towards long-term goals over the course of months or years. Perhaps most\\ntransformative will be the acceleration of scientific discovery. AI agents will autonomously design and con-\\nduct experiments in fields like materials science, medicine, or hardware design. By continuously learning\\nfrom the results of their own experiments, these agents could rapidly explore new frontiers of knowledge,\\nleading to the development of novel materials, drugs, and technologies at an unprecedented pace.\\nHowever, this new era also presents significant and novel challenges. While the automation of human\\n7', mimetype='text/plain', start_char_idx=0, end_char_idx=4280, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.31541437923177906)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de396aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
